---
description: llama+lora
---

# ğŸ¦™ Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆ

[github](https://github.com/Facico/Chinese-Vicuna/tree/master)

<mark style="background-color:green;">gitä»“åº“æä¾›äº†ä¸€ä¸ªé’ˆå¯¹llamaç³»åˆ—å·¥ç¨‹å¾ˆå¥½çš„QAæ–‡æ¡£ï¼š</mark>[<mark style="background-color:green;">https://github.com/Facico/Chinese-Vicuna/blob/master/docs/notes.md</mark>](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/notes.md)

### æ¦‚è¿°

é‰´äº[llama](https://github.com/facebookresearch/llama),[alpaca](https://github.com/tatsu-lab/stanford\_alpaca),[guanaco](https://github.com/Guanaco-Model/Guanaco-Model.github.io)ç­‰ç¾Šé©¼æ¨¡å‹çš„ç ”å‘æˆåŠŸï¼Œæœ¬é¡¹ç›®åŸºäºLLaMA+instructionæ•°æ®æ„å»ºä¸€ä¸ªä¸­æ–‡çš„ç¾Šé©¼æ¨¡å‹ï¼Œå¹¶å¸®åŠ©å¤§å®¶èƒ½å¿«é€Ÿå­¦ä¼šä½¿ç”¨å¼•å…¥è‡ªå·±çš„æ•°æ®ï¼Œå¹¶è®­ç»ƒå‡ºå±äºè‡ªå·±çš„å°ç¾Šé©¼ï¼ˆVicunaï¼‰

ä»£ç åŸºäºalpaca-loraå¼€å‘ï¼Œ[https://github.com/tloen/alpaca-lora](https://github.com/tloen/alpaca-lora)

å‚æ•°é«˜æ•ˆï¼Œæ˜¾å¡å‹å¥½ï¼Œéƒ¨ç½²ç®€æ˜“ï¼š

* åœ¨ä¸€å¼ 2080Tiï¼ˆ11Gï¼‰ä¸Šå¯ä»¥å¯¹Llama-7Bè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒ ([7b-instruct](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-7b-belle-and-guanaco))
* åœ¨ä¸€å¼ 3090ï¼ˆ24Gï¼‰ä¸Šå¯ä»¥å¯¹Llama-13Bè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒ ([13b-instruct](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-13b-belle-and-guanaco))
* å³ä½¿æ˜¯é•¿åº¦ä¸º2048çš„å¯¹è¯ï¼Œåœ¨3090ä¸Šä¹Ÿå¯ä»¥å®ŒæˆLlama-7Bçš„å¾®è°ƒï¼›ä½¿ç”¨5ä¸‡æ¡æ•°æ®å³å¯æœ‰ä¸é”™æ•ˆæœ ([chatv1](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-7b-chatv1))
* é¢†åŸŸå¾®è°ƒçš„ä¾‹å­ï¼šåŒ»å­¦é—®ç­” å’Œ æ³•å¾‹é—®ç­”ã€‚([medical](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-continue-finetune-7epoch-cMedQA2) and [legal](https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-7b-legal-lora))
* æ”¯æŒ`qlora-4bit`ï¼Œä½¿ç”¨4bitå¯ä»¥åœ¨2080Tiä¸Šå®Œæˆ13Bçš„è®­ç»ƒ
* å¯åœ¨2080Ti/3090ä¸Šè½»æ¾éƒ¨ç½²ï¼Œæ”¯æŒå¤šå¡åŒæ—¶æ¨ç†ï¼Œå¯è¿›ä¸€æ­¥é™ä½æ˜¾å­˜å ç”¨

é¡¹ç›®åŒ…æ‹¬

* finetuneæ¨¡å‹çš„ä»£ç 
* æ¨ç†çš„ä»£ç 
* ä»…ä½¿ç”¨CPUæ¨ç†çš„ä»£ç  (ä½¿ç”¨C++)
* ä¸‹è½½/è½¬æ¢/é‡åŒ–Facebook llama.ckptçš„å·¥å…·
* å…¶ä»–åº”ç”¨

### è®­ç»ƒä¸€ä¸ªloraéœ€è¦ä»€ä¹ˆ

#### ä»£ç 

* æ­¤ä»£ç åŸºäºalpaca-loraå¼€å‘ï¼Œ[https://github.com/tloen/alpaca-lora](https://github.com/tloen/alpaca-lora)
* è¿™æ˜¯ä¸€å¥—æ¯”è¾ƒç®€å•çš„ä»£ç ï¼ŒåŸºæœ¬æ€è·¯å°±æ˜¯ç”¨[PEFT](https://github.com/huggingface/peft)çš„loraæ¥å£+transformerçš„trainer+instructionçš„æ•°æ®é…ç½®

#### æ•°æ®

è¿™äº›æ•°æ®å¾ˆå¤šéƒ½åƒalpacaé‚£æ ·ï¼Œä½¿ç”¨chatgptçš„æ¥å£ï¼Œç”Ÿæˆé«˜è´¨é‡çš„instructionæ•°æ®ã€‚

* [Belle](https://github.com/LianjiaTech/BELLE)
* [guanaco](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset)

æ•°æ®æ ¼å¼æ¯”è¾ƒç®€å•ï¼ŒåŸºæœ¬å¦‚ä¸‹ï¼š

* {% code fullWidth="true" %}
  ```
  {
  'instruction': 
  'input': 
  'output'
  }
  ```
  {% endcode %}

å³éœ€è¦ä¸€ä¸ªæŒ‡ä»¤ï¼Œä¸€ä¸ªinputï¼Œä¸€ä¸ªoutputã€‚ç”±äºæ•°æ®å¤„ç†çš„æ—¶å€™æ˜¯ç›´æ¥å°†instructionå’Œinputè¿æ¥èµ·æ¥çš„ï¼Œæ‰€ä»¥æ•°æ®å…¶å®å¯ä»¥åªéœ€è¦instructionå’Œoutputï¼Œå¦‚

* ```
  {
  'instruction': "ç”¨ä¸€å¥è¯æè¿°åœ°çƒä¸ºä»€ä¹ˆæ˜¯ç‹¬ä¸€æ— äºŒçš„ã€‚\\n\n"
  'input': ""
  'output': "åœ°çƒä¸Šæœ‰é€‚å®œç”Ÿå‘½å­˜åœ¨çš„æ¡ä»¶å’Œå¤šæ ·åŒ–çš„ç”Ÿå‘½å½¢å¼ã€‚"
  }
  ```

<mark style="background-color:green;">æ•°æ®ä¸‹è½½ï¼š</mark>

* é“¾æ¥: [https://pan.baidu.com/s/1WSxuhSAotl14ifaAiz5eKw?pwd=b4kb](https://pan.baidu.com/s/1WSxuhSAotl14ifaAiz5eKw?pwd=b4kb) æå–ç : b4kb
* é“¾æ¥: [https://drive.google.com/file/d/1tzXVhS74m-EtoFot7hEc005LDeZGPit\_/view?usp=sharing](https://drive.google.com/file/d/1tzXVhS74m-EtoFot7hEc005LDeZGPit\_/view?usp=sharing)
* é“¾æ¥: [https://huggingface.co/datasets/Chinese-Vicuna/guanaco\_belle\_merge\_v1.0](https://huggingface.co/datasets/Chinese-Vicuna/guanaco\_belle\_merge\_v1.0)

#### ä¸Šæ¸¸æ¨¡å‹

LLAMA-7B

#### loraæ¨¡å‹

* ä»“åº“æä¾›äº†ä¸€ä¸ªåœ¨ä¸Šé¢æ··åˆæ•°æ®ä¸Šè®­ç»ƒçš„loraæ¨¡å‹
  * ä½ å¯ä»¥ä»huggingfaceä¸ŠåŠ è½½ç°æˆçš„æ¨¡å‹æˆ–å…¶ä»–loraæ¨¡å‹ï¼ŒåŠ è½½æ–¹å¼å‚è€ƒ[generate.py](https://github.com/Facico/Chinese-Vicuna/blob/master/generate.py)
    * `Chinese-Vicuna/Chinese-Vicuna-lora-7b-belle-and-guanaco`
    * `Chinese-Vicuna/Chinese-Vicuna-lora-13b-belle-and-guanaco`
  * æ¨¡å‹ä½¿ç”¨çš„æ˜¯8bit+lora+256 tokens
  * æ›´å¤šæ¨¡å‹è¯·æŸ¥çœ‹ï¼š[https://huggingface.co/Chinese-Vicuna](https://huggingface.co/Chinese-Vicuna)

#### è®¾å¤‡

* è®­ç»ƒï¼š<mark style="color:red;">ä¸€å¼ 2080Tiå³å¯</mark>ã€‚ç”±äºæ•°æ®é•¿åº¦éƒ½åœ¨256ï¼ˆä»£ç è®¾ç½®ä¸ºcutoff\_lenï¼Œé»˜è®¤é˜¶æ®µé•¿åº¦ï¼‰ä»¥å†…ï¼Œå¤§æ¦‚å ç”¨9Gæ˜¾å­˜ã€‚
  * <mark style="color:red;">70wçš„æ•°æ®ï¼Œ3ä¸ªepochï¼Œä¸€å¼ 2080Tiå¤§æ¦‚200h</mark>
  * <mark style="color:orange;">13Béœ€è¦18Gå·¦å³æ˜¾å­˜ï¼ˆåœ¨3090ä¸Šå¯ä»¥å°†æ•°æ®é•¿åº¦å¼€åˆ°2048ï¼‰</mark>
* æ¨ç†ï¼šä¸€å¼ 2080Tiå³å¯ï¼ˆ7Bï¼‰,åŒæ—¶æ”¯æŒå¤šå¡æ¨ç†ï¼ˆå·®ä¸å¤šå‡åŒ€è´Ÿè½½ï¼ŒæŸå¼ å¡ä¼šè´Ÿè½½é«˜ä¸€ç‚¹ï¼‰ã€‚
* æˆ‘ä»¬å¯¹çº¯CPUä¸Šæ¨ç†ä¹Ÿè¿›è¡Œäº†æ”¯æŒï¼Œè¯¦æƒ…è§[`tools`](https://github.com/Facico/Chinese-Vicuna/blob/master/tools)

### ä½¿ç”¨æ–¹æ³•

**8bit**

```
bash scripts/finetune.sh
```

è¿™é‡Œéœ€è¦æ³¨æ„çš„å‚æ•°å¦‚ä¸‹

* `TOT_CUDA`ï¼Œå¡«å†™éœ€è¦ä½¿ç”¨çš„GPUç¼–å·ï¼Œå¦‚`TOT_CUDA="0,1,2,3"`
* `PORT`ï¼Œå¡«å†™å¯¹åº”çš„ç«¯å£
* `DATA_PATH`ï¼Œå¡«å†™å¯¹åº”çš„æ•°æ®ä½ç½®ï¼Œæ ¼å¼ä¸ºjson
* `OUTPUT_PATH`ï¼Œä¿å­˜æ¨¡å‹çš„ç›¸å¯¹è·¯å¾„
* `MODEL_PATH`ï¼Œä¸Šæ¸¸æ¨¡å‹
* `wandb`ï¼šè¿™æ˜¯ä¸€ä¸ªè®­ç»ƒå¯è§†åŒ–å·¥å…·ï¼Œè„šæœ¬ä¸­é»˜è®¤æ²¡å¼€ï¼Œå¯ä»¥åœ¨è„šæœ¬ä¸­åŠ å…¥"--wandb"æ¥å¼€å¯

**4bit**

```
bash scripts/finetune_4bit.sh
```

**ç”¨äºå¯¹è¯å¼å¾®è°ƒ**

```
bash scripts/finetune_chat.sh
```

**ç”¨äºä¸èƒ½å¼€8bitæƒ…å†µ/ç”¨äºfp16çš„æŒ‡ä»¤å¼å¾®è°ƒ**

```
bash scripts/finetune_deepspeed.sh
```

* use\_deepspeedï¼šè®¾ç½®ä¸º1è¡¨ç¤ºè¦ç”¨ deepspeedï¼Œå¦åˆ™ä½¿ç”¨fp16 **å•å¡è®­ç»ƒ**

```
CUDA_VISIBLE_DEVICES=0 python finetune.py --data_path merge.json --test_size 2000
```

* è¿™ä¸ªtest\_sizeä¸èƒ½å¤§äºæ•°æ®å¤§å°

**inferenceå¹¶ä½¿ç”¨gradioç”Ÿæˆä¸€ä¸ªç½‘é¡µï¼ˆç”¨äºæŒ‡ä»¤é—®ç­”ï¼‰**

```
bash scripts/generate.sh
```

è¿™é‡Œéœ€è¦æ³¨æ„çš„å‚æ•°å¦‚ä¸‹

* BASE\_MODELï¼Œä¸Šæ¸¸æ¨¡å‹
* LORA\_PATHï¼Œloraæ¨¡å‹çš„checkpointæ–‡ä»¶å¤¹
  * è¿™é‡Œè¦æ³¨æ„çš„æ˜¯ï¼Œloraæ¨¡å‹åŠ è½½çš„configå¿…é¡»æ˜¯"adapter\_config.json"ï¼Œæ¨¡å‹åå­—å¿…é¡»æ˜¯â€œadapter\_model.binâ€ï¼Œä¸è¿‡åœ¨è®­ç»ƒçš„æ—¶å€™ä¼šè‡ªåŠ¨ä¿å­˜ä¸ºâ€œpytorch\_model.binâ€ï¼Œè€Œ"adapter\_config.json"å’Œâ€œadapter\_model.binâ€ä¼šåœ¨å…¨éƒ¨è®­ç»ƒç»“æŸä¹‹åä¿å­˜
    * å¦‚æœä½ æ˜¯åœ¨è®­ç»ƒçš„checkpointä¸­è½½å…¥çš„loraæ¨¡å‹ï¼Œä»£ç é‡Œä¼šè‡ªåŠ¨å¸®ä½ æŠŠæœ¬åœ°çš„"config-sample/adapter\_config.json"å¤åˆ¶åˆ°å¯¹åº”ç›®å½•ï¼Œå¹¶æŠŠâ€œpytorch\_model.binâ€æ”¹åä¸ºâ€œadapter\_model.binâ€
  * ä¹Ÿå¯ä»¥æ˜¯ä»»æ„çš„huggingfaceä¸Šå¯¹åº”llama 7Bçš„loraæ¨¡å‹ï¼Œå¦‚ï¼š`Facico/Chinese-Vicuna-lora-7b-3epoch-belle-and-guanaco`
* USE\_LOCALï¼Œè®¾ç½®ä¸º1æ—¶ä¼šæ£€æŸ¥æœ¬åœ°æ¨¡å‹é…ç½®
* ä½¿ç”¨çš„æ—¶å€™ï¼Œ"max\_tokens"æ ¹æ®è‡ªå·±ç”µè„‘çš„æ˜¾å­˜æ¥è®¾ç½®ï¼Œå¦‚æœç”Ÿæˆçš„å†…å®¹äº§ç”Ÿäº†å¾ˆå¤šé‡å¤ä¿¡æ¯ï¼Œå¯ä»¥å°†"Repetition Penalty"è°ƒé«˜

**å¤šè½®äº¤äº’**

ç”±äºæˆ‘ä»¬åœ¨è®­ç»ƒçš„æ—¶å€™ç”¨çš„åŸºæœ¬æ˜¯æŒ‡ä»¤çš„promptï¼Œæ‰€ä»¥é—²èŠå¯¹è¯èƒ½åŠ›è¿˜æ¯”è¾ƒå·®ï¼Œåç»­å°†å¢åŠ è¿™ä¸€éƒ¨åˆ†çš„è®­ç»ƒã€‚

```
bash scripts/chat.sh
```

*   ä½¿ç”¨gradioæ„é€ çš„ä¸€ä¸ªç®€å•çš„äº¤äº’ç•Œé¢ï¼Œå¯ä»¥æ ¹æ®è‡ªå·±çš„æœºå™¨è®¾ç½®max\_memoryï¼ˆå®ƒä¼šæˆªå–å†å²å¯¹è¯çš„åé¢max\_memoryéƒ¨åˆ†ï¼‰


* è¿™ä¸ªè„šæœ¬ä½¿ç”¨çš„promptå’Œgenerate.shä¸­ä½¿ç”¨çš„ä¸å¤ªä¸€æ ·ï¼Œè¿™ä¸ªè„šæœ¬çš„promptä¸ºå¯¹è¯å½¢å¼çš„ï¼Œå¦‚ä¸‹`The following is a conversation between an AI assistant called Bot and a human user called User.`

åŒæ—¶ï¼Œä¸ºäº†æ›´å¥½çš„äº¤äº’ä½“éªŒï¼Œæˆ‘ä»¬è‡ªå·±å®ç°äº†æµå¼è¾“å‡ºï¼ˆæ‰“å­—æœºå¼ï¼‰äº¤äº’çš„chatbotï¼Œæ”¯æŒbeam searchã€repetiion penaltyçš„è®¾ç½®ï¼Œèƒ½æ¸…ç©ºå†å²è®°å½•ï¼Œé€‰æ‹©ä¸åŒçš„å…¨å±€instructionç­‰ã€‚

#### **ç®—åŠ›é…ç½®--**è®­ç»ƒçš„é…ç½®æ˜¯æ€ä¹ˆæ ·çš„ï¼Ÿé™¤äº†7Bèƒ½è®­ç»ƒå—ï¼Ÿå¤§äº256æˆªæ–­é•¿åº¦èƒ½è®­ç»ƒå—ï¼Ÿæœ€ä½é…ç½®æ˜¯ä»€ä¹ˆï¼Ÿ

è®­ç»ƒçš„ç¡¬ä»¶è¦æ±‚ä¸»è¦å–å†³äºè®­ç»ƒåºåˆ—é•¿åº¦ã€`mirco batch size`å¤§å°ï¼Œä»¥åŠè®­ç»ƒæ—¶é—´ä½ æ˜¯å¦èƒ½æ¥å—ã€‚

* mirco batch sizeè®¾ç½®å°ä¸€ç‚¹ï¼Œ11Gçš„2080Tiä¹Ÿèƒ½è·‘æ›´å¤§é•¿åº¦çš„
* mirco batch sizeè®¾ç½®ä¸º1ï¼Œ24Gçš„3090Tiå¯ä»¥è®­ç»ƒ2048é•¿åº¦çš„
* 4090çš„ç®—åŠ›çº¦ä¸º3090ä¸¤å€ï¼ŒA100-40Gçš„int8ç®—åŠ›ä¸4090ç›¸è¿‘

<table><thead><tr><th width="138"></th><th></th><th width="150"></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td><strong>Model</strong></td><td><strong>GPU</strong></td><td><strong>lora+fp16+512</strong></td><td></td><td><strong>lora+int8+256</strong></td><td></td><td><strong>lora+int8+512</strong></td><td></td><td><strong>lora+int8+2048</strong></td><td></td></tr><tr><td></td><td></td><td>speed</td><td>size</td><td>speed</td><td>size</td><td>speed</td><td>size</td><td>speed</td><td>size</td></tr><tr><td>LLaMA-7B</td><td>2080Ti</td><td></td><td></td><td>0.2h/w</td><td>11G</td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>3090</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>4090</td><td>0.3h/w</td><td>20G</td><td></td><td></td><td>0.8h/w</td><td></td><td>3.5h/w</td><td>20G</td></tr><tr><td>LLaMA-13B</td><td>3090</td><td></td><td></td><td>0.9h/w</td><td></td><td></td><td></td><td>7.5h/w</td><td>24G</td></tr><tr><td></td><td>4090</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table>

**æ³¨æ„ï¼š**

* int8 ä»…åŠ è½½æ¨¡å‹æ˜¾å­˜å ç”¨ï¼ˆVRAMï¼‰ç¡¬ç›˜ç©ºé—´å¤§å°ï¼Œæ¯”å¦‚7Bå¤§æ¦‚8Gå·¦å³ï¼Œ13Bå¤§æ¦‚14Gå·¦å³ï¼›å¦‚æœæ˜¯fp16å’Œfp32åˆ™ç›¸åº”ä¹˜2å’Œä¹˜4
* è®­ç»ƒçš„æ—¶å€™ï¼Œæ˜¾å­˜å ç”¨å’Œè®­ç»ƒçš„é€Ÿåº¦å’Œåºåˆ—é•¿åº¦å¯†åˆ‡ç›¸å…³ï¼Œæ¯”å¦‚åºåˆ—é•¿åº¦256æ˜¾å­˜å ç”¨ä¸è¶…è¿‡11Gï¼Œè¿™ä¸ªæ—¶å€™å¯ä»¥åœ¨2080Tiä¸Šå¾®è°ƒ7Bï¼Œåºåˆ—é•¿åº¦å¦‚æœæ˜¯2048ï¼Œåˆ™æ˜¾å­˜å ç”¨ä¼šéª¤å¢åˆ°20Gï¼Œå°±è¦ä¸Š3090æˆ–è€…4090æ‰èƒ½å¾®è°ƒ7Bäº†
* åŒç†ï¼Œ13Båœ¨3090/4090ä¸Šæ˜¯å¯ä»¥å¾®è°ƒçš„ï¼Œ2048çš„æ—¶å€™microbatché™åˆ°1ä¹Ÿæ˜¯å¯ä»¥è·‘çš„
* å¦å¤–ï¼Œæœ‰äººå‘ç°åœ¨A100-40Gä¸Šå¢å¤§batchæ²¡æœ‰æ˜æ˜¾çš„æé€Ÿï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºint8æ¯”è¾ƒåƒç®—åŠ›ï¼ˆæ¯”å¦‚ç›¸åŒçš„é…ç½®fp16å¿«äºint8ï¼‰ï¼Œç®—åŠ›åƒæ»¡åå¢åŠ batchä¹Ÿä¸èƒ½æé«˜ååé‡ï¼Œå¦ä¸€æ–¹é¢A100-40Gçš„int8ç®—åŠ›å…¶å®å’Œ4090å·®ä¸å¤šã€‚



### å…·ä½“æ¡ˆä¾‹

åŒ»å­¦é—®ç­”å‚ç›´è¯­æ–™çš„continue-finetuneï¼Œå‚è€ƒ[Chinese-Vicuna-medical](https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-medical.md)



### Reference

LLaMA paper: [https://arxiv.org/abs/2302.13971v1](https://arxiv.org/abs/2302.13971v1)

Self-Instruct paper: [https://arxiv.org/abs/2212.10560](https://arxiv.org/abs/2212.10560)

Data generation: [https://github.com/LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) and [https://guanaco-model.github.io/](https://guanaco-model.github.io/)

The first work: [https://github.com/tatsu-lab/stanford\_alpaca](https://github.com/tatsu-lab/stanford\_alpaca)

Lora paperï¼š[https://arxiv.org/pdf/2106.09685.pdf](https://arxiv.org/pdf/2106.09685.pdf)



\


